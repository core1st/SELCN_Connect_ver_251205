import streamlit as st
import pandas as pd
import altair as alt
import numpy as np
from datetime import datetime
import io

# ==============================================================================
# 1. í˜ì´ì§€ ë° ê¸°ë³¸ ì„¤ì •
# ==============================================================================
st.set_page_config(page_title="ì—¬ê°ë…¸ì„ ë¶€ ì—°ê²° ë¶„ì„ê¸°", layout="wide")

st.markdown(
    """
    <style>
    [data-testid="stSidebar"] {
        min-width: 350px;
        max-width: 350px;
    }
    /* Bank View ë²„íŠ¼ í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ë§ (Bold & Size Up) */
    div.stButton > button {
        font-weight: bold !important;
        font-size: 15px !important;
        border: 1px solid #ddd;
    }
    div.stButton > button p {
        font-weight: bold !important;
        font-size: 15px !important;
    }
    </style>
    """,
    unsafe_allow_html=True,
)
st.title("ì—°ê²° ìŠ¤ì¼€ì¤„ ë¶„ì„ ì•± VER.2.0")

# --- ëª¨ë“œ ì„ íƒ (ì‚¬ì´ë“œë°”) ---
analysis_mode = st.sidebar.radio(
    "ê¸°ëŠ¥ ëª¨ë“œ ì„ íƒ",
    ["ìŠ¤ì¼€ì¤„ ë°ì´í„° ë³€í™˜", "ë‹¨ì¼ ìŠ¤ì¼€ì¤„ ë¶„ì„", "ë‘ ìŠ¤ì¼€ì¤„ ë¹„êµ ë¶„ì„"]
)

# --- [NOTICE] ë°ì´í„° ì‘ì„± ê°€ì´ë“œ ---
if analysis_mode != "ìŠ¤ì¼€ì¤„ ë°ì´í„° ë³€í™˜":
    with st.expander("[í•„ë…] ë¶„ì„ìš© ë°ì´í„°(CSV) ì‘ì„± ì–‘ì‹ ê°€ì´ë“œ", expanded=False):
        st.markdown("""
        ##### 1. í•„ìˆ˜ ì»¬ëŸ¼
        * **SEASON**: ì‹œì¦Œ (ì˜ˆ: S26)
        * **FLT NO**: í¸ëª… (ì˜ˆ: '081')
        * **ORGN**: ì¶œë°œì§€ ê³µí•­
        * **DEST** (ë˜ëŠ” DESTINATION): ë„ì°©ì§€ ê³µí•­
        * **STD / STA**: ì‹œê°„ (HH:MM)
        * **OPS**: í•­ê³µì‚¬ ì½”ë“œ
        * **ROUTE**: ë…¸ì„  êµ¬ë¶„ (ì˜ˆ: ë¯¸ì£¼ë…¸ì„ , ë™ë‚¨ì•„ë…¸ì„ , CHN, JPN ë“±) -> **ìƒ‰ìƒ êµ¬ë¶„ ê¸°ì¤€**
        * **êµ¬ë¶„**: `To ICN` (ë„ì°©) / `From ICN` (ì¶œë°œ)
        """)

# ==============================================================================
# 2. ê³µí†µ í•¨ìˆ˜ ì •ì˜
# ==============================================================================

@st.cache_data
def load_data(file):
    encodings = ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr']
    for enc in encodings:
        try:
            file.seek(0)
            df = pd.read_csv(file, encoding=enc)
            df.columns = df.columns.str.strip()
            if 'DESTINATION' in df.columns:
                df.rename(columns={'DESTINATION': 'DEST'}, inplace=True)

            required = ['OPS', 'FLT NO', 'êµ¬ë¶„', 'STD', 'STA', 'ORGN', 'DEST', 'ROUTE']
            if all(col in df.columns for col in required):
                for col in ['êµ¬ë¶„', 'FLT NO', 'ROUTE', 'OPS', 'ORGN', 'DEST']:
                    if col in df.columns:
                        df[col] = df[col].astype(str).str.strip()
                return df
        except:
            continue
    return None

def time_to_minutes(t_str):
    try:
        h, m = map(int, t_str.split(':'))
        return h * 60 + m
    except:
        return None

def get_time_slot(time_str):
    try:
        dt = datetime.strptime(time_str, "%H:%M")
        hour = dt.hour
        next_hour = hour + 1
        return f"{hour:02d}ì‹œ~{next_hour:02d}ì‹œ"
    except:
        return "Time Error"

def color_route_style(val):
    val_upper = str(val).upper()
    if any(x in val_upper for x in ['CHN', 'ì¤‘êµ­']): return 'background-color: #d9534f; color: white; font-weight: bold;'
    elif any(x in val_upper for x in ['SEA', 'ë™ë‚¨ì•„']): return 'background-color: #f0ad4e; color: black; font-weight: bold;'
    elif any(x in val_upper for x in ['JPN', 'ì¼ë³¸']): return 'background-color: #5bc0de; color: black; font-weight: bold;'
    elif any(x in val_upper for x in ['AME', 'ë¯¸ì£¼']): return 'background-color: #0275d8; color: white; font-weight: bold;'
    elif any(x in val_upper for x in ['EUR', 'êµ¬ì£¼', 'ìœ ëŸ½']): return 'background-color: #5cb85c; color: white; font-weight: bold;'
    elif any(x in val_upper for x in ['OCE', 'ëŒ€ì–‘ì£¼']): return 'background-color: #5bc0de; color: white; font-weight: bold;'
    elif any(x in val_upper for x in ['CIS', 'ëŸ¬ì‹œì•„']): return 'background-color: #777; color: white; font-weight: bold;'
    else: return ''

def apply_scoring(df, min_limit, max_limit, score_weights, time_thresholds):
    if df.empty: return df
    def calculate_row_score(row):
        if row['Status'] != 'Connected': return 0
        conn_min = row['Conn_Min']
        if conn_min <= time_thresholds[0]: return score_weights[0]
        elif conn_min <= time_thresholds[1]: return score_weights[1]
        elif conn_min <= time_thresholds[2]: return score_weights[2]
        elif conn_min <= time_thresholds[3]: return score_weights[3]
        else: return score_weights[4]
    df['Score'] = df.apply(calculate_row_score, axis=1)
    return df

def render_score_settings(key_suffix, min_mct, max_ct):
    with st.sidebar.expander("ì—°ê²° ìŠ¤ì½”ì–´ ì„¤ì •", expanded=False):
        c1, c2, c3, c4, c5 = st.columns(5)
        step = (max_ct - min_mct) / 5
        with c1: s1 = st.number_input("S1", 10, key=f's1{key_suffix}'); t1 = int(min_mct + step)
        with c2: s2 = st.number_input("S2", 8, key=f's2{key_suffix}'); t2 = int(min_mct + step*2)
        with c3: s3 = st.number_input("S3", 6, key=f's3{key_suffix}'); t3 = int(min_mct + step*3)
        with c4: s4 = st.number_input("S4", 4, key=f's4{key_suffix}'); t4 = int(min_mct + step*4)
        with c5: s5 = st.number_input("S5", 2, key=f's5{key_suffix}')
        return [s1, s2, s3, s4, s5], [t1, t2, t3, t4], None

def analyze_connections_flexible(df, min_limit, max_limit, group_a_routes, group_a_ops, group_b_routes, group_b_ops):
    results = []
    def analyze_one_direction(start_routes, start_ops, end_routes, end_ops, direction_label):
        inbound = df[(df['ROUTE'].isin(start_routes)) & (df['OPS'].isin(start_ops)) & (df['êµ¬ë¶„'] == 'To ICN')].copy()
        outbound = df[(df['ROUTE'].isin(end_routes)) & (df['OPS'].isin(end_ops)) & (df['êµ¬ë¶„'] == 'From ICN')].copy()
        if inbound.empty or outbound.empty: return []
        merged = pd.merge(inbound.assign(k=1), outbound.assign(k=1), on='k', suffixes=('_IN', '_OUT'))
        local_results = []
        for _, row in merged.iterrows():
            arr = time_to_minutes(row['STA_IN'])
            dep = time_to_minutes(row['STD_OUT'])
            if arr is not None and dep is not None:
                diff = dep - arr
                if diff < 0: diff += 1440 
                status = 'Connected' if min_limit <= diff <= max_limit else 'Disconnect'
                local_results.append({
                    'Direction': direction_label,
                    'Inbound_Route': row['ROUTE_IN'], 'Outbound_Route': row['ROUTE_OUT'],
                    'Inbound_OPS': row['OPS_IN'], 'Outbound_OPS': row['OPS_OUT'],
                    'Inbound_Flt_No': f"{row['OPS_IN']}{row['FLT NO_IN']}", 
                    'Outbound_Flt_No': f"{row['OPS_OUT']}{row['FLT NO_OUT']}",
                    'From': row['ORGN_IN'], 'Via': 'ICN', 'To': row['DEST_OUT'],
                    'Hub_Arr_Time': row['STA_IN'], 'Hub_Dep_Time': row['STD_OUT'],
                    'Conn_Min': diff, 'Status': status
                })
        return local_results

    results.extend(analyze_one_direction(group_a_routes, group_a_ops, group_b_routes, group_b_ops, "Group A -> Group B"))
    is_same_group = set(group_a_routes) == set(group_b_routes) and set(group_a_ops) == set(group_b_ops)
    if not is_same_group:
        results.extend(analyze_one_direction(group_b_routes, group_b_ops, group_a_routes, group_a_ops, "Group B -> Group A"))

    cols = ['Direction', 'Inbound_Route', 'Outbound_Route', 'Inbound_OPS', 'Outbound_OPS', 'Inbound_Flt_No', 'Outbound_Flt_No', 'From', 'Via', 'To', 'Hub_Arr_Time', 'Hub_Dep_Time', 'Conn_Min', 'Status']
    if not results: return pd.DataFrame(columns=cols)
    return pd.DataFrame(results)[cols]

# --- ë¹„êµ ë¶„ì„ìš© í•¨ìˆ˜ë“¤ ---
def compare_schedules(df1, df2, min_limit, max_limit, group_a_routes, group_a_ops, group_b_routes, group_b_ops, score_weights, time_thresholds):
    raw_result1 = analyze_connections_flexible(df1, min_limit, max_limit, group_a_routes, group_a_ops, group_b_routes, group_b_ops)
    raw_result2 = analyze_connections_flexible(df2, min_limit, max_limit, group_a_routes, group_a_ops, group_b_routes, group_b_ops)
    
    result1 = apply_scoring(raw_result1, min_limit, max_limit, score_weights, time_thresholds)
    result2 = apply_scoring(raw_result2, min_limit, max_limit, score_weights, time_thresholds)
    
    def create_key(row): return f"{row['Inbound_Flt_No']}_{row['Outbound_Flt_No']}_{row['From']}_{row['To']}"
    
    if not result1.empty: result1['Key'] = result1.apply(create_key, axis=1)
    else: result1['Key'] = []
    if not result2.empty: result2['Key'] = result2.apply(create_key, axis=1)
    else: result2['Key'] = []

    conn1_keys = set(result1[result1['Status'] == 'Connected']['Key'])
    conn2_keys = set(result2[result2['Status'] == 'Connected']['Key'])
    
    common_keys = conn1_keys & conn2_keys
    lost_keys = conn1_keys - conn2_keys
    new_keys = conn2_keys - conn1_keys
    
    lost_connections = result1[result1['Key'].isin(lost_keys) & (result1['Status']=='Connected')].copy()
    new_connections = result2[result2['Key'].isin(new_keys) & (result2['Status']=='Connected')].copy()
    
    time_changes = pd.DataFrame()
    if common_keys:
        c1 = result1[result1['Key'].isin(common_keys)][['Key', 'Conn_Min', 'Score', 'Hub_Arr_Time', 'Hub_Dep_Time']].set_index('Key')
        c2 = result2[result2['Key'].isin(common_keys)][['Key', 'Conn_Min', 'Score', 'Hub_Arr_Time', 'Hub_Dep_Time']].set_index('Key')
        
        merged = c1.join(c2, lsuffix='_1', rsuffix='_2')
        time_changes = merged[(merged['Conn_Min_1'] != merged['Conn_Min_2']) | (merged['Score_1'] != merged['Score_2'])].reset_index()
        meta = result2[['Key', 'Inbound_Flt_No', 'Outbound_Flt_No', 'From', 'To']].drop_duplicates()
        time_changes = pd.merge(time_changes, meta, on='Key', how='left')

    return {
        'result1': result1, 'result2': result2,
        'stats': {
            'total_score_1': result1[result1['Status']=='Connected']['Score'].sum(),
            'total_score_2': result2[result2['Status']=='Connected']['Score'].sum(),
            'total_conn_1': len(conn1_keys), 'total_conn_2': len(conn2_keys),
            'lost_count': len(lost_keys), 'new_count': len(new_keys)
        },
        'lost_connections': lost_connections,
        'new_connections': new_connections,
        'time_changes': time_changes
    }

def compare_flights(df1, df2):
    def create_flight_key(row): return f"{row['OPS']}{row['FLT NO']}_{row['ORGN']}_{row['DEST']}"
    d1 = df1.copy(); d2 = df2.copy()
    d1['Key'] = d1.apply(create_flight_key, axis=1)
    d2['Key'] = d2.apply(create_flight_key, axis=1)
    k1 = set(d1['Key']); k2 = set(d2['Key'])
    removed = d1[d1['Key'].isin(k1 - k2)]
    added = d2[d2['Key'].isin(k2 - k1)]
    common = k1 & k2
    c1 = d1[d1['Key'].isin(common)].set_index('Key')[['STD', 'STA']]
    c2 = d2[d2['Key'].isin(common)].set_index('Key')[['STD', 'STA']]
    m = c1.join(c2, lsuffix='_OLD', rsuffix='_NEW')
    changed = m[(m['STD_OLD'] != m['STD_NEW']) | (m['STA_OLD'] != m['STA_NEW'])].reset_index()
    return {
        'removed': removed, 'added': added, 'time_changed': changed,
        'stats': {'total_1': len(k1), 'total_2': len(k2)}
    }

# [UPDATED] ë°ì´í„° ë³€í™˜ í•¨ìˆ˜ (ë‚´ì¬í™”ëœ Mapping)
def preprocess_export_data(file, target_date):
    try:
        df = pd.read_csv(file)
        target_dt = pd.to_datetime(target_date)
        target_weekday = target_dt.weekday() # 0=Mon
        
        # [INTERNAL MAP] ê³µí•­-ì§€ì—­ ë§¤í•‘ ë‚´ì¬í™”
        route_map = {
            # ì¼ë³¸ (Japan)
            'NRT': 'ì¼ë³¸ë…¸ì„ ', 'HND': 'ì¼ë³¸ë…¸ì„ ', 'KIX': 'ì¼ë³¸ë…¸ì„ ', 'FUK': 'ì¼ë³¸ë…¸ì„ ', 'NGO': 'ì¼ë³¸ë…¸ì„ ',
            'CTS': 'ì¼ë³¸ë…¸ì„ ', 'OKA': 'ì¼ë³¸ë…¸ì„ ', 'KOJ': 'ì¼ë³¸ë…¸ì„ ', 'KMJ': 'ì¼ë³¸ë…¸ì„ ', 'HIJ': 'ì¼ë³¸ë…¸ì„ ',
            'TAK': 'ì¼ë³¸ë…¸ì„ ', 'MYJ': 'ì¼ë³¸ë…¸ì„ ', 'FSZ': 'ì¼ë³¸ë…¸ì„ ', 'KIJ': 'ì¼ë³¸ë…¸ì„ ', 'OKJ': 'ì¼ë³¸ë…¸ì„ ',
            'KKJ': 'ì¼ë³¸ë…¸ì„ ', 'AOJ': 'ì¼ë³¸ë…¸ì„ ', 'AXT': 'ì¼ë³¸ë…¸ì„ ', 'HNA': 'ì¼ë³¸ë…¸ì„ ', 'KUH': 'ì¼ë³¸ë…¸ì„ ',
            'MMB': 'ì¼ë³¸ë…¸ì„ ', 'OIT': 'ì¼ë³¸ë…¸ì„ ', 'SDJ': 'ì¼ë³¸ë…¸ì„ ', 'UBJ': 'ì¼ë³¸ë…¸ì„ ', 'UKB': 'ì¼ë³¸ë…¸ì„ ',
            'NGS': 'ì¼ë³¸ë…¸ì„ ', 'KMQ': 'ì¼ë³¸ë…¸ì„ ',
            
            # ì¤‘êµ­ (China)
            'PEK': 'ì¤‘êµ­ë…¸ì„ ', 'PVG': 'ì¤‘êµ­ë…¸ì„ ', 'SHA': 'ì¤‘êµ­ë…¸ì„ ', 'CAN': 'ì¤‘êµ­ë…¸ì„ ', 'HKG': 'ì¤‘êµ­ë…¸ì„ ',
            'TPE': 'ì¤‘êµ­ë…¸ì„ ', 'TSN': 'ì¤‘êµ­ë…¸ì„ ', 'SHE': 'ì¤‘êµ­ë…¸ì„ ', 'TAO': 'ì¤‘êµ­ë…¸ì„ ', 'CKG': 'ì¤‘êµ­ë…¸ì„ ',
            'CTU': 'ì¤‘êµ­ë…¸ì„ ', 'DLC': 'ì¤‘êµ­ë…¸ì„ ', 'HGH': 'ì¤‘êµ­ë…¸ì„ ', 'HRB': 'ì¤‘êµ­ë…¸ì„ ', 'KMG': 'ì¤‘êµ­ë…¸ì„ ',
            'NKG': 'ì¤‘êµ­ë…¸ì„ ', 'SZX': 'ì¤‘êµ­ë…¸ì„ ', 'TNA': 'ì¤‘êµ­ë…¸ì„ ', 'WEH': 'ì¤‘êµ­ë…¸ì„ ', 'XIY': 'ì¤‘êµ­ë…¸ì„ ',
            'XMN': 'ì¤‘êµ­ë…¸ì„ ', 'YNJ': 'ì¤‘êµ­ë…¸ì„ ', 'YNT': 'ì¤‘êµ­ë…¸ì„ ', 'CGQ': 'ì¤‘êµ­ë…¸ì„ ', 'CSX': 'ì¤‘êµ­ë…¸ì„ ',
            'CGO': 'ì¤‘êµ­ë…¸ì„ ', 'FOC': 'ì¤‘êµ­ë…¸ì„ ', 'HAK': 'ì¤‘êµ­ë…¸ì„ ', 'HFE': 'ì¤‘êµ­ë…¸ì„ ', 'JJN': 'ì¤‘êµ­ë…¸ì„ ',
            'KWE': 'ì¤‘êµ­ë…¸ì„ ', 'NNG': 'ì¤‘êµ­ë…¸ì„ ', 'SYX': 'ì¤‘êµ­ë…¸ì„ ', 'WUH': 'ì¤‘êµ­ë…¸ì„ ', 'XNN': 'ì¤‘êµ­ë…¸ì„ ',
            'DYG': 'ì¤‘êµ­ë…¸ì„ ', 'MDG': 'ì¤‘êµ­ë…¸ì„ ', 'MFM': 'ì¤‘êµ­ë…¸ì„ ', 'RMQ': 'ì¤‘êµ­ë…¸ì„ ',
            
            # ë™ë‚¨ì•„ (Southeast Asia)
            'BKK': 'ë™ë‚¨ì•„ë…¸ì„ ', 'SIN': 'ë™ë‚¨ì•„ë…¸ì„ ', 'SGN': 'ë™ë‚¨ì•„ë…¸ì„ ', 'HAN': 'ë™ë‚¨ì•„ë…¸ì„ ', 'MNL': 'ë™ë‚¨ì•„ë…¸ì„ ',
            'CEB': 'ë™ë‚¨ì•„ë…¸ì„ ', 'HKT': 'ë™ë‚¨ì•„ë…¸ì„ ', 'DAD': 'ë™ë‚¨ì•„ë…¸ì„ ', 'KUL': 'ë™ë‚¨ì•„ë…¸ì„ ', 'CGK': 'ë™ë‚¨ì•„ë…¸ì„ ',
            'DPS': 'ë™ë‚¨ì•„ë…¸ì„ ', 'CNX': 'ë™ë‚¨ì•„ë…¸ì„ ', 'PNH': 'ë™ë‚¨ì•„ë…¸ì„ ', 'RGN': 'ë™ë‚¨ì•„ë…¸ì„ ', 'VTE': 'ë™ë‚¨ì•„ë…¸ì„ ',
            'CXR': 'ë™ë‚¨ì•„ë…¸ì„ ', 'DVO': 'ë™ë‚¨ì•„ë…¸ì„ ', 'KBV': 'ë™ë‚¨ì•„ë…¸ì„ ', 'KLO': 'ë™ë‚¨ì•„ë…¸ì„ ', 'LPQ': 'ë™ë‚¨ì•„ë…¸ì„ ',
            'REP': 'ë™ë‚¨ì•„ë…¸ì„ ', 'USM': 'ë™ë‚¨ì•„ë…¸ì„ ', 'CRK': 'ë™ë‚¨ì•„ë…¸ì„ ', 'GUM': 'ë™ë‚¨ì•„ë…¸ì„ ', 'PQC': 'ë™ë‚¨ì•„ë…¸ì„ ',
            'KTI': 'ë™ë‚¨ì•„ë…¸ì„ ', 'KTM': 'ë™ë‚¨ì•„ë…¸ì„ ',

            # ë¯¸ì£¼ (Americas)
            'LAX': 'ë¯¸ì£¼ë…¸ì„ ', 'JFK': 'ë¯¸ì£¼ë…¸ì„ ', 'SFO': 'ë¯¸ì£¼ë…¸ì„ ', 'SEA': 'ë¯¸ì£¼ë…¸ì„ ', 'ATL': 'ë¯¸ì£¼ë…¸ì„ ',
            'ORD': 'ë¯¸ì£¼ë…¸ì„ ', 'LAS': 'ë¯¸ì£¼ë…¸ì„ ', 'HNL': 'ë¯¸ì£¼ë…¸ì„ ', 'YVR': 'ë¯¸ì£¼ë…¸ì„ ', 'YYZ': 'ë¯¸ì£¼ë…¸ì„ ',
            'DFW': 'ë¯¸ì£¼ë…¸ì„ ', 'IAD': 'ë¯¸ì£¼ë…¸ì„ ', 'BOS': 'ë¯¸ì£¼ë…¸ì„ ', 'DTW': 'ë¯¸ì£¼ë…¸ì„ ', 'MSP': 'ë¯¸ì£¼ë…¸ì„ ',
            'SLC': 'ë¯¸ì£¼ë…¸ì„ ',  # ê´Œì€ ë³´í†µ ë¯¸ì£¼ ë˜ëŠ” ëŒ€ì–‘ì£¼ë¡œ ë¶„ë¥˜ (ì—¬ê¸°ì„  ë¯¸ì£¼)
            'ANC': 'ë¯¸ì£¼ë…¸ì„ ', 'MIA': 'ë¯¸ì£¼ë…¸ì„ ', 'IAH': 'ë¯¸ì£¼ë…¸ì„ ',
            
            # êµ¬ì£¼/ìœ ëŸ½ (Europe)
            'LHR': 'êµ¬ì£¼ë…¸ì„ ', 'CDG': 'êµ¬ì£¼ë…¸ì„ ', 'FRA': 'êµ¬ì£¼ë…¸ì„ ', 'FCO': 'êµ¬ì£¼ë…¸ì„ ', 'MXP': 'êµ¬ì£¼ë…¸ì„ ',
            'BCN': 'êµ¬ì£¼ë…¸ì„ ', 'MAD': 'êµ¬ì£¼ë…¸ì„ ', 'AMS': 'êµ¬ì£¼ë…¸ì„ ', 'ZRH': 'êµ¬ì£¼ë…¸ì„ ', 'IST': 'êµ¬ì£¼ë…¸ì„ ',
            'PRG': 'êµ¬ì£¼ë…¸ì„ ', 'BUD': 'êµ¬ì£¼ë…¸ì„ ', 'VIE': 'êµ¬ì£¼ë…¸ì„ ', 'MUC': 'êµ¬ì£¼ë…¸ì„ ', 'LIS': 'êµ¬ì£¼ë…¸ì„ ',
            'ZAG': 'êµ¬ì£¼ë…¸ì„ ', 'WAW': 'êµ¬ì£¼ë…¸ì„ ', 'OSL': 'êµ¬ì£¼ë…¸ì„ ', 'ARN': 'êµ¬ì£¼ë…¸ì„ ', 'CPH': 'êµ¬ì£¼ë…¸ì„ ',
            'HEL': 'êµ¬ì£¼ë…¸ì„ ', 'SVO': 'êµ¬ì£¼ë…¸ì„ ', 'LED': 'êµ¬ì£¼ë…¸ì„ ', 'TLV': 'êµ¬ì£¼ë…¸ì„ ', # ì¤‘ë™ ì¼ë¶€ í¬í•¨ ê°€ëŠ¥
            'DXB': 'êµ¬ì£¼ë…¸ì„ ', # í¸ì˜ìƒ ì¤‘ë™ í¬í•¨
            
            # ëŒ€ì–‘ì£¼ (Oceania)
            'SYD': 'ëŒ€ì–‘ì£¼ë…¸ì„ ', 'BNE': 'ëŒ€ì–‘ì£¼ë…¸ì„ ', 'AKL': 'ëŒ€ì–‘ì£¼ë…¸ì„ ', 'NAN': 'ëŒ€ì–‘ì£¼ë…¸ì„ ', 'ROR': 'ëŒ€ì–‘ì£¼ë…¸ì„ ',
            'SPN': 'ëŒ€ì–‘ì£¼ë…¸ì„ ',
            
            # CIS
            'UBN': 'CISë…¸ì„ ', 'VVO': 'CISë…¸ì„ ', 'ALA': 'CISë…¸ì„ ', 'TAS': 'CISë…¸ì„ ', 'KHV': 'CISë…¸ì„ ',
            'YKS': 'CISë…¸ì„ ', 'IKT': 'CISë…¸ì„ '
        }
        
        processed_rows = []
        
        for _, row in df.iterrows():
            try:
                # PERIOD
                period_str = str(row['PERIOD']).strip()
                if '~' in period_str:
                    s_str, e_str = period_str.split('~')
                    start_date = pd.to_datetime(s_str.strip())
                    end_date = pd.to_datetime(e_str.strip())
                    if not (start_date <= target_dt <= end_date): continue
                
                # DAY
                days_ops = str(row['DAY']).strip()
                data_idx = target_weekday + 1
                if str(data_idx) not in days_ops: continue
            except: continue

            # Data Parsing
            raw_flt = str(row['FLT']).strip()
            ops = raw_flt[:2]
            flt_no = raw_flt[2:]
            
            orgn = str(row['DEP']).strip()
            dest = str(row['ARR']).strip()
            std = str(row['STD']).strip()
            sta = str(row['STA']).strip()
            
            # êµ¬ë¶„ ë° Route ë§¤í•‘ ëŒ€ìƒ í™•ì¸
            if orgn == 'ICN':
                gubun = 'From ICN'
                check_port = dest
            elif dest == 'ICN':
                gubun = 'To ICN'
                check_port = orgn
            else:
                continue
            
            # Route Map ì ìš©
            route = route_map.get(check_port, 'ê¸°íƒ€ë…¸ì„ ')
            
            processed_rows.append({
                'SEASON': 'S26',
                'FLT NO': flt_no, 'ORGN': orgn, 'DEST': dest,
                'STD': std, 'STA': sta, 'OPS': ops,
                'ROUTE': route, 'êµ¬ë¶„': gubun
            })
            
        return pd.DataFrame(processed_rows)

    except Exception as e:
        st.error(f"ë°ì´í„° ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

# ==============================================================================
# 3. ë©”ì¸ ì‹¤í–‰ ë¡œì§
# ==============================================================================

# [MODE 1] ìŠ¤ì¼€ì¤„ ë°ì´í„° ë³€í™˜ê¸°
if analysis_mode == "ìŠ¤ì¼€ì¤„ ë°ì´í„° ë³€í™˜":
    st.header("Raw ìŠ¤ì¼€ì¤„ ë°ì´í„° ë³€í™˜")
    st.info("BASEì˜ WEEKLY SKD ë©”ë‰´ë¥¼ í†µí•´ ì¶”ì¶œí•œ export.csv íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë¶„ì„í•  ë‚ ì§œë¥¼ ì„ íƒí•˜ë©´ ë¶„ì„ê°€ëŠ¥í•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤")
    
    col1, col2 = st.columns(2)
    with col1:
        raw_file = st.file_uploader("ì›ë³¸ íŒŒì¼ ì—…ë¡œë“œ (export.csv)", type="csv")
    with col2:
        target_date = st.date_input("ë¶„ì„í•  ì¼ì ì„ íƒ", datetime.today())
        
    if st.button("ë³€í™˜ ì‹¤í–‰", type="primary"):
        if raw_file:
            with st.spinner("ë°ì´í„° ë³€í™˜ ë° í•„í„°ë§ ì¤‘..."):
                converted_df = preprocess_export_data(raw_file, target_date)
                
                if converted_df is not None and not converted_df.empty:
                    st.success(f"ë³€í™˜ ì™„ë£Œ! ì´ {len(converted_df)}ê°œì˜ ìš´í•­í¸ ì¶”ì¶œ.")
                    st.dataframe(converted_df.head())
                    
                    st.session_state['converted_data'] = converted_df
                    
                    csv = converted_df.to_csv(index=False).encode('utf-8-sig')
                    st.download_button("ë³€í™˜ëœ íŒŒì¼ ë‹¤ìš´ë¡œë“œ", csv, f"Schedule_{target_date}.csv", "text/csv")
                else:
                    st.warning("ì¡°ê±´ì— ë§ëŠ” ìš´í•­ ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ë³€í™˜ ì‹¤íŒ¨.")
        else:
            st.error("íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

# [MODE 2] ë‹¨ì¼ ìŠ¤ì¼€ì¤„ ë¶„ì„
elif analysis_mode == "ë‹¨ì¼ ìŠ¤ì¼€ì¤„ ë¶„ì„":
    st.sidebar.header("ë¶„ì„ ì„¤ì •")
    
    df = None
    use_converted = False
    
    if 'converted_data' in st.session_state:
        st.sidebar.success(f"ë³€í™˜ëœ ë°ì´í„° ê°ì§€ë¨ ({len(st.session_state['converted_data'])}ê±´)")
        if st.sidebar.checkbox("ë³€í™˜ëœ ë°ì´í„° ì‚¬ìš©í•˜ê¸°", value=True):
            df = st.session_state['converted_data']
            use_converted = True
            
    if not use_converted:
        uploaded_file = st.sidebar.file_uploader("ë¶„ì„ìš© ë°ì´í„° (CSV)", type="csv")
        if uploaded_file:
            df = load_data(uploaded_file)

    if df is not None:
        if not use_converted:
            st.sidebar.success(f"íŒŒì¼ ë¡œë“œ: {len(df)}ê±´")
            
        all_routes = sorted(df['ROUTE'].unique().tolist())
        all_ops = sorted(df['OPS'].unique().tolist())
        
        st.sidebar.markdown("---")
        routes_a = st.sidebar.multiselect("ê·¸ë£¹ A ë…¸ì„ ", all_routes, default=[all_routes[0]] if all_routes else None, key='ra')
        ops_a = st.sidebar.multiselect("ê·¸ë£¹ A í•­ê³µì‚¬", all_ops, default=all_ops, key='oa')
        
        st.sidebar.markdown("â¬‡ï¸ â¬†ï¸")
        
        routes_b = st.sidebar.multiselect("ê·¸ë£¹ B ë…¸ì„ ", all_routes, default=[all_routes[1]] if len(all_routes)>1 else all_routes, key='rb')
        ops_b = st.sidebar.multiselect("ê·¸ë£¹ B í•­ê³µì‚¬", all_ops, default=all_ops, key='ob')
        
        st.sidebar.markdown("---")
        min_mct = st.sidebar.number_input("Min CT (ë¶„)", 0, 300, 60, 5)
        max_ct = st.sidebar.number_input("Max CT (ë¶„)", 60, 2880, 300, 60)
        
        score_weights, time_thresholds, _ = render_score_settings("single", min_mct, max_ct)
        
        if st.button("ë¶„ì„ ì‹œì‘", type="primary"):
            if not routes_a or not routes_b:
                st.error("ê·¸ë£¹ ë…¸ì„ ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("ë¶„ì„ ì¤‘..."):
                    raw_df = analyze_connections_flexible(df, min_mct, max_ct, routes_a, ops_a, routes_b, ops_b)
                    result_df = apply_scoring(raw_df, min_mct, max_ct, score_weights, time_thresholds)
                    st.session_state['analysis_result'] = result_df
                    st.session_state['analysis_done'] = True
                    st.session_state['group_names'] = (", ".join(routes_a), ", ".join(routes_b))
                    st.session_state['source_df'] = df

        if st.session_state.get('analysis_done'):
            result_df = st.session_state['analysis_result']
            source_df = st.session_state.get('source_df', df)
            g_name_a, g_name_b = st.session_state.get('group_names', ("A", "B"))
            
            tab1, tab2, tab3, tab4, tab5 = st.tabs(["ê²°ê³¼ ìš”ì•½", "ìƒì„¸ ë¦¬ìŠ¤íŠ¸", "ê³µí•­ë³„ ì‹¬ì¸µ ë¶„ì„", "í—ˆë¸Œ ìŠ¤ì¼€ì¤„", "Bank ì‹œê°í™”"])
            
            with tab1:
                st.info(f"ë¶„ì„ ê¸°ì¤€: [{g_name_a}] â†” [{g_name_b}]")
                if not result_df.empty:
                    m1, m2 = st.columns(2)
                    m1.metric("ì´ ì—°ê²° í¸ìˆ˜", f"{len(result_df[result_df['Status']=='Connected']):,}í¸")
                    m2.metric("í‰ê·  ìŠ¤ì½”ì–´", f"{result_df[result_df['Status']=='Connected']['Score'].mean():.1f}ì ")
                    st.dataframe(result_df.groupby(['Inbound_Route', 'Outbound_Route', 'Status']).size().unstack(fill_value=0), use_container_width=True)
                else:
                    st.warning("ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

            with tab2:
                if not result_df.empty:
                    st.dataframe(result_df[result_df['Status']=='Connected'], use_container_width=True)
            
            with tab3: # ê³µí•­ë³„ ë¶„ì„
                if result_df.empty:
                     st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.markdown("### ê³µí•­ ê¸°ì¤€ ì—°ê²°ì„± ë¶„ì„")
                    src_a = result_df[result_df['Direction'] == 'Group A -> Group B']['From'].unique()
                    dst_a = result_df[result_df['Direction'] == 'Group B -> Group A']['To'].unique()
                    candidates = set(src_a) | set(dst_a)
                    if 'ICN' in candidates: candidates.remove('ICN')
                    airport_list = sorted(list(candidates))
                    
                    if not airport_list:
                        st.info("ì°¨íŠ¸ë¥¼ ê·¸ë¦´ ìˆ˜ ìˆëŠ” ê³µí•­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.markdown(f"**ê·¸ë£¹ A ({g_name_a}) ì†Œì† ê³µí•­ ì„ íƒ**")
                        selected_airport = st.selectbox("ğŸ“ ê³µí•­ ì„ íƒ", airport_list)
                        connected_data = result_df[result_df['Status']=='Connected']
                        
                        c1, c2 = st.columns(2)
                        with c1:
                            out_df = connected_data[(connected_data['Direction'] == 'Group A -> Group B') & (connected_data['From'] == selected_airport)]
                            if not out_df.empty:
                                chart = alt.Chart(out_df).mark_circle(size=150).encode(
                                    x='To', y='Conn_Min', color='Inbound_Flt_No', 
                                    tooltip=['To', 'Conn_Min', 'Inbound_Flt_No', 'Outbound_Flt_No', 'Hub_Arr_Time', 'Hub_Dep_Time']
                                ).properties(height=500, title=f"{selected_airport} ë„ì°© -> ICN ì—°ê²°").interactive()
                                st.altair_chart(chart, use_container_width=True)
                            else: st.info("ë°ì´í„° ì—†ìŒ")
                        with c2:
                            in_df = connected_data[(connected_data['Direction'] == 'Group B -> Group A') & (connected_data['To'] == selected_airport)]
                            if not in_df.empty:
                                chart = alt.Chart(in_df).mark_circle(size=150).encode(
                                    x='From', y='Conn_Min', color='Outbound_Flt_No', 
                                    tooltip=['From', 'Conn_Min', 'Outbound_Flt_No', 'Inbound_Flt_No', 'Hub_Arr_Time', 'Hub_Dep_Time']
                                ).properties(height=500, title=f"ICN ì¶œë°œ -> {selected_airport} ë„ì°©").interactive()
                                st.altair_chart(chart, use_container_width=True)
                            else: st.info("ë°ì´í„° ì—†ìŒ")

            with tab4: # í—ˆë¸Œ ìŠ¤ì¼€ì¤„
                st.markdown("### ICN í—ˆë¸Œ ìŠ¤ì¼€ì¤„ ëª¨ë‹ˆí„°ë§")
                st.caption("ë„ì°©/ì¶œë°œ í•­ê³µí¸ì„ 1ì‹œê°„ ë‹¨ìœ„ë¡œ ë¶„ë¥˜í•˜ì—¬ ë…¸ì„ ë³„ ìƒ‰ìƒ ì½”ë“œë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.")
                arr_raw = source_df[source_df['êµ¬ë¶„'] == 'To ICN'].copy()
                dep_raw = source_df[source_df['êµ¬ë¶„'] == 'From ICN'].copy()
                arr_raw['ì‹œê°„ëŒ€'] = arr_raw['STA'].apply(get_time_slot)
                dep_raw['ì‹œê°„ëŒ€'] = dep_raw['STD'].apply(get_time_slot)
                arr_raw['Sort_Key'] = arr_raw['STA'].apply(time_to_minutes)
                dep_raw['Sort_Key'] = dep_raw['STD'].apply(time_to_minutes)
                arr_raw = arr_raw.sort_values(by='Sort_Key', ascending=True)
                dep_raw = dep_raw.sort_values(by='Sort_Key', ascending=True)
                cols_arr = ['ì‹œê°„ëŒ€', 'STA', 'ROUTE', 'ORGN', 'OPS', 'FLT NO']
                cols_dep = ['ì‹œê°„ëŒ€', 'STD', 'ROUTE', 'DEST', 'OPS', 'FLT NO']
                styled_arr = arr_raw[cols_arr].style.map(color_route_style, subset=['ROUTE'])
                styled_dep = dep_raw[cols_dep].style.map(color_route_style, subset=['ROUTE'])
                col_arr, col_dep = st.columns(2)
                with col_arr:
                    st.subheader("ğŸ›¬ ICN ë„ì°© (Arrival)")
                    st.dataframe(styled_arr, use_container_width=True, height=800, hide_index=True)
                with col_dep:
                    st.subheader("ğŸ›« ICN ì¶œë°œ (Departure)")
                    st.dataframe(styled_dep, use_container_width=True, height=800, hide_index=True)

            with tab5: # Interactive Bank
                st.markdown("### Connection Bank (Interactive)")
                st.caption("ì™¼ìª½(Inbound)ì„ í´ë¦­í•˜ë©´ ì—°ê²° ê°€ëŠ¥í•œ ì˜¤ë¥¸ìª½(Outbound) í¸ì´ ê°•ì¡°ë©ë‹ˆë‹¤.")

                if 'selected_inbound_flt' not in st.session_state:
                    st.session_state['selected_inbound_flt'] = None

                target_df = result_df[(result_df['Status'] == 'Connected') & (result_df['Direction'] == 'Group A -> Group B')].copy()

                if target_df.empty:
                    st.warning("ì¡°ê±´ì— ë§ëŠ” ì—°ê²° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    in_cols = ['Inbound_Flt_No', 'Inbound_OPS', 'Inbound_Route', 'From', 'Hub_Arr_Time']
                    df_in = target_df[in_cols].drop_duplicates()
                    df_in.columns = ['FLT', 'OPS', 'ROUTE', 'PORT', 'TIME']
                    df_in['Time_Min'] = df_in['TIME'].apply(time_to_minutes)
                    df_in['Hour'] = (df_in['Time_Min'] // 60) % 24
                    
                    out_cols = ['Outbound_Flt_No', 'Outbound_OPS', 'Outbound_Route', 'To', 'Hub_Dep_Time']
                    df_out = target_df[out_cols].drop_duplicates()
                    df_out.columns = ['FLT', 'OPS', 'ROUTE', 'PORT', 'TIME']
                    df_out['Time_Min'] = df_out['TIME'].apply(time_to_minutes)
                    df_out['Hour'] = (df_out['Time_Min'] // 60) % 24

                    df_in = df_in.sort_values(by=['Time_Min', 'ROUTE'])
                    df_out = df_out.sort_values(by=['Time_Min', 'ROUTE'])

                    def get_route_color_hex(route_val):
                        val_upper = str(route_val).upper()
                        if any(x in val_upper for x in ['CHN', 'ì¤‘êµ­']): return '#d9534f'
                        elif any(x in val_upper for x in ['SEA', 'ë™ë‚¨ì•„']): return '#f0ad4e'
                        elif any(x in val_upper for x in ['JPN', 'ì¼ë³¸']): return '#5bc0de'
                        elif any(x in val_upper for x in ['AME', 'ë¯¸ì£¼']): return '#0275d8'
                        elif any(x in val_upper for x in ['EUR', 'êµ¬ì£¼']): return '#5cb85c'
                        return '#777777'

                    def create_outbound_card(row, is_highlighted, is_dimmed):
                        bg_color = get_route_color_hex(row['ROUTE'])
                        opacity = "0.2" if is_dimmed else "1.0"
                        box_shadow = "0px 0px 8px 2px #FFD700" if is_highlighted else "1px 1px 3px rgba(0,0,0,0.1)"
                        border_style = f"4px solid {bg_color}"
                        html = f"""
                        <div style="opacity:{opacity}; border-left:{border_style}; padding:10px; margin-bottom:8px; background:white; box-shadow:{box_shadow}; transition:all 0.3s ease; border-radius:4px;">
                            <div style="display:flex; justify-content:space-between; align-items:center;">
                                <span style="font-weight:bold; color:#333; font-size:1.1em;">{row['TIME']}</span>
                                <span style="background-color:{bg_color}; color:white; padding:2px 6px; border-radius:3px; font-size:0.7em;">{row['ROUTE']}</span>
                            </div>
                            <div style="margin-top:4px; display:flex; justify-content:space-between; color:#555;">
                                <span>{row['FLT']}</span>
                                <span style="font-weight:bold;">{row['PORT']}</span>
                            </div>
                        </div>"""
                        return html

                    connected_outbounds = []
                    if st.session_state['selected_inbound_flt']:
                        connected_outbounds = target_df[target_df['Inbound_Flt_No'] == st.session_state['selected_inbound_flt']]['Outbound_Flt_No'].tolist()

                    for hour in range(24):
                        in_group = df_in[df_in['Hour'] == hour]
                        out_group = df_out[df_out['Hour'] == hour]

                        if not in_group.empty or not out_group.empty:
                            st.markdown(f"<div style='background:#f0f2f6; padding:5px; margin:10px 0; font-weight:bold; text-align:center; border-radius:5px;'>{hour:02d}:00 - {hour+1:02d}:00</div>", unsafe_allow_html=True)
                            c1, c2 = st.columns(2)
                            with c1:
                                for _, row in in_group.iterrows():
                                    flt = row['FLT']
                                    icon = "ğŸ”µ" if st.session_state['selected_inbound_flt'] == flt else "âšª"
                                    if st.button(f"{icon} [{row['TIME']}] {flt} ({row['PORT']})", key=f"btn_{flt}", use_container_width=True):
                                        st.session_state['selected_inbound_flt'] = flt
                                        st.rerun()
                            with c2:
                                for _, row in out_group.iterrows():
                                    flt_out = row['FLT']
                                    is_highlight = (st.session_state['selected_inbound_flt'] and flt_out in connected_outbounds)
                                    is_dim = (st.session_state['selected_inbound_flt'] and not is_highlight)
                                    st.markdown(create_outbound_card(row, is_highlight, is_dim), unsafe_allow_html=True)
                    
                    if st.session_state['selected_inbound_flt']:
                        if st.button("ğŸ”„ ì„ íƒ ì´ˆê¸°í™”"):
                            st.session_state['selected_inbound_flt'] = None
                            st.rerun()

# [MODE 3] ë‘ ìŠ¤ì¼€ì¤„ ë¹„êµ ë¶„ì„
elif analysis_mode == "ë‘ ìŠ¤ì¼€ì¤„ ë¹„êµ ë¶„ì„":
    st.sidebar.header("âš™ï¸ ë¹„êµ ë¶„ì„ ì„¤ì •")
    f1 = st.sidebar.file_uploader("ğŸ“‚ ìŠ¤ì¼€ì¤„ 1 (Before)", type="csv", key="f1")
    f2 = st.sidebar.file_uploader("ğŸ“‚ ìŠ¤ì¼€ì¤„ 2 (After)", type="csv", key="f2")
    
    if f1 and f2:
        try:
            df1 = load_data(f1)
            df2 = load_data(f2)
            
            all_routes = sorted(set(df1['ROUTE'].unique().tolist() + df2['ROUTE'].unique().tolist()))
            all_ops = sorted(set(df1['OPS'].unique().tolist() + df2['OPS'].unique().tolist()))
            
            st.sidebar.markdown("---")
            routes_a = st.sidebar.multiselect("ê·¸ë£¹ A ë…¸ì„ ", all_routes, key='cmp_ra')
            ops_a = st.sidebar.multiselect("ê·¸ë£¹ A í•­ê³µì‚¬", all_ops, default=all_ops, key='cmp_oa')
            routes_b = st.sidebar.multiselect("ê·¸ë£¹ B ë…¸ì„ ", all_routes, key='cmp_rb')
            ops_b = st.sidebar.multiselect("ê·¸ë£¹ B í•­ê³µì‚¬", all_ops, default=all_ops, key='cmp_ob')
            
            min_mct = st.sidebar.number_input("Min CT", 0, 300, 60, 5, key='cmp_min')
            max_ct = st.sidebar.number_input("Max CT", 60, 2880, 300, 60, key='cmp_max')
            score_weights_cmp, time_thresholds_cmp, _ = render_score_settings("cmp", min_mct, max_ct)
            
            if st.button("ğŸ” ë¹„êµ ë¶„ì„ ì‹œì‘", type="primary"):
                 if routes_a and routes_b:
                    with st.spinner("ë¹„êµ ë¶„ì„ ì¤‘..."):
                        conn_cmp = compare_schedules(df1, df2, min_mct, max_ct, routes_a, ops_a, routes_b, ops_b, score_weights_cmp, time_thresholds_cmp)
                        flt_cmp = compare_flights(df1, df2)
                        st.session_state['conn_comparison'] = conn_cmp
                        st.session_state['flight_comparison'] = flt_cmp
                        st.session_state['comparison_done'] = True
                        st.session_state['cmp_group_names'] = (", ".join(routes_a), ", ".join(routes_b))
                 else:
                     st.error("ê·¸ë£¹ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            
            if st.session_state.get('comparison_done'):
                conn_cmp = st.session_state['conn_comparison']
                flt_cmp = st.session_state['flight_comparison']
                g_name_a, g_name_b = st.session_state.get('cmp_group_names', ("A", "B"))
                
                t1, t2, t3, t4 = st.tabs(["ğŸ“Š ë¹„êµ ìš”ì•½", "âœˆï¸ í•­ê³µí¸ ë³€ê²½", "ğŸ”— ì—°ê²° ë³€ê²½", "â±ï¸ ì‹œê°„/ìŠ¤ì½”ì–´ ë³€ê²½"])
                
                with t1:
                    st.info(f"**ë¶„ì„ ê¸°ì¤€**: [{g_name_a}] â†” [{g_name_b}]")
                    sc_col1, sc_col2, sc_col3 = st.columns(3)
                    with sc_col1: st.metric("ìŠ¤ì¼€ì¤„ 1 ì´ì ", f"{conn_cmp['stats']['total_score_1']:,.0f}ì ")
                    with sc_col2: st.metric("ìŠ¤ì¼€ì¤„ 2 ì´ì ", f"{conn_cmp['stats']['total_score_2']:,.0f}ì ")
                    with sc_col3: 
                        diff = conn_cmp['stats']['total_score_2'] - conn_cmp['stats']['total_score_1']
                        st.metric("ì ìˆ˜ ì°¨ì´", f"{diff:+,.0f}ì ", delta=diff)
                    st.markdown("---")
                    c1, c2 = st.columns(2)
                    with c1:
                        st.markdown("#### âœˆï¸ í•­ê³µí¸ ë³€ê²½")
                        st.metric("ì´ í•­ê³µí¸ ì°¨ì´", flt_cmp['stats']['total_2'] - flt_cmp['stats']['total_1'])
                    with c2:
                        st.markdown("#### ğŸ”— ì—°ê²° ë³€ê²½")
                        st.metric("ì´ ì—°ê²° í¸ìˆ˜ ì°¨ì´", conn_cmp['stats']['total_conn_2'] - conn_cmp['stats']['total_conn_1'])

                with t2:
                    if not flt_cmp['time_changed'].empty:
                        st.markdown("#### ğŸ•’ ì‹œê°„ ë³€ê²½ëœ í•­ê³µí¸")
                        st.dataframe(flt_cmp['time_changed'])
                    col_rem, col_add = st.columns(2)
                    with col_rem:
                        st.markdown("#### âŒ ì‚­ì œëœ í•­ê³µí¸")
                        if not flt_cmp['removed'].empty: st.dataframe(flt_cmp['removed'])
                    with col_add:
                        st.markdown("#### ğŸ†• ì‹ ê·œ í•­ê³µí¸")
                        if not flt_cmp['added'].empty: st.dataframe(flt_cmp['added'])
                
                with t3:
                    st.markdown("**âŒ ì‚¬ë¼ì§„ ì—°ê²°**")
                    st.dataframe(conn_cmp['lost_connections'])
                    st.markdown("**ğŸ†• ìƒˆë¡œìš´ ì—°ê²°**")
                    st.dataframe(conn_cmp['new_connections'])
                
                with t4:
                    st.markdown("**â±ï¸ ì—°ê²° ì‹œê°„/ìŠ¤ì½”ì–´ ë³€ê²½ ìƒì„¸**")
                    st.dataframe(conn_cmp['time_changes'])

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            import traceback
            st.text(traceback.format_exc())